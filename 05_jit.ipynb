{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c49b7230",
   "metadata": {},
   "source": [
    "### The magic sauce over numpy\n",
    "\n",
    "Transforms are what Jax adds on top of numpy. This is more of an advanced thing to understand and if you wish to skip and come back later, you can do it. It's fine\n",
    "\n",
    "So about transforms in Jax. There are these transforms: `jit`, `grad`, `pmap`, `vmap`.\n",
    "\n",
    "This notebook is about jit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce8614d",
   "metadata": {},
   "source": [
    "### jit()\n",
    "\n",
    "Jax calls itself accelerated numpy. Or a faster numpy. Or however you interprete it. jit is one of the key components in this acceleration. What jit does is that it keeps a copy of your functions in the cache which can be executed faster than a regular function call. But how? \n",
    "\n",
    "\n",
    "\n",
    "#### Translating computer programs (or a rather CS101 refresher)\n",
    "\n",
    "Computers only understand 1's and 0's (in other words, binary numbers). So when you try to run your code, it needs to be translated into binary numbers first. This process isn't straightforward. There are multiple levels of what CS junkies call abstractions. One possible abstraction hierarchy can be like this (or what it used to look like before [llvm](https://llvm.org/) and [clang](https://clang.llvm.org/) came). \n",
    "\n",
    "\n",
    "```\n",
    "-------> Your code \n",
    "        -------> **Translator**\n",
    "                -------> Assembler (based on the instruction Set that your CPU / GPU maker made, also known as ISA) \n",
    "                        -------> Binary (executable)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "This translator part in the middle can be either a Compiler or an Interpreter. Compiler takes your entire code file and translates it at once. There's a whole field of study in CS on compiler design if you want to look into that abyss. Anyway, since compilers translate or compile the whole file at once, you can add various optimizations (memory, speed) and enforce checks at translation or compile time to make sure your code has reduced amount of errors. Compiled programs are also, by comparison, faster. (Video Games, Operating Systems are prime examples.) **AND you need to compile only once!** (terms and conditions apply)\n",
    "\n",
    "Python on the other hand is interpreted. Interpreter translates one line at a time and **you have to intereprete everytime** you want to run your code. The process is slow and you can't enforce the same checks and optimizations like a compiler. Everything is known when the code is encountered so errors can't be reduced beforehand. So when Jax tries to cache your code for faster recall, the regular python design holds it back. Instead, Jax uses a compiler called XLA, which compiles your python code and caches it.\n",
    "\n",
    "\n",
    "And oh, JIT means just in time compilation (thank me later :) )\n",
    "\n",
    "So let's check how much of a performance benefit jit adds on top of regular code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77c46ac5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T01:12:34.348010Z",
     "start_time": "2023-02-08T01:12:34.116136Z"
    }
   },
   "outputs": [],
   "source": [
    "import jax as J\n",
    "from jax import jit, random\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb65fb7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T01:12:35.714470Z",
     "start_time": "2023-02-08T01:12:35.305384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([-0.10502207, -0.56205004, -0.56485987, -1.7063935 ,\n",
       "             -1.3647023 , -0.42215332,  1.0077653 ,  0.9922631 ,\n",
       "             -0.61236995], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = random.PRNGKey(123)\n",
    "\n",
    "x = random.normal(key, shape=(9, ))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29a9bb95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T01:12:42.052635Z",
     "start_time": "2023-02-08T01:12:37.961241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.9 µs ± 701 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return jnp.sin(x) + jnp.cos(x)\n",
    "\n",
    "%timeit f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef095714",
   "metadata": {},
   "source": [
    "With jit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a7a596",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T01:12:57.421263Z",
     "start_time": "2023-02-08T01:12:45.502012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.7 µs ± 319 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "f_with_jit = jit(f)\n",
    "\n",
    "%timeit f_with_jit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7497cc1",
   "metadata": {},
   "source": [
    "See that wall time difference ? That's like real fast!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe078dbb",
   "metadata": {},
   "source": [
    "#### Alternate syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cefd33f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T01:13:20.152293Z",
     "start_time": "2023-02-08T01:13:08.452267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.3 µs ± 55.3 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "@jit\n",
    "def f(x):\n",
    "    return jnp.sin(x) + jnp.cos(x)\n",
    "\n",
    "%timeit f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1c5b11",
   "metadata": {},
   "source": [
    "### But it's not all sunshine....\n",
    "\n",
    "Well caching and speeding up is nice but if your code changes, jit will have to compile it again. This adds some overhead and repeated compilations can make code execution slow, for example inside a loop. Also, not everything in python is supported in jax transformations, such as jit. Your code should be side-effect free (for starters, not have pythonic `loops`, `print` statements and `if-else` conditionals) and jax enforces a very functional programming approach. As a result you may not be able to jit every part of your code. \n",
    "\n",
    "This is where jax is different from Tensorflow or Pytorch. You've to think which parts of your code are going to be covered by transformations, which parts only take care of computations and which parts take care of loops and conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036864e3",
   "metadata": {},
   "source": [
    "#### What my python code becomes after XLA compilation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b12f4a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T01:13:30.340764Z",
     "start_time": "2023-02-08T01:13:30.339058Z"
    }
   },
   "outputs": [],
   "source": [
    "from jax import make_jaxpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05e20425",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T01:13:34.179960Z",
     "start_time": "2023-02-08T01:13:34.175268Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[9]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n",
       "    \u001b[39m\u001b[22m\u001b[22mb\u001b[35m:f32[9]\u001b[39m = xla_call[\n",
       "      call_jaxpr={ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; c\u001b[35m:f32[9]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n",
       "          \u001b[39m\u001b[22m\u001b[22md\u001b[35m:f32[9]\u001b[39m = sin c\n",
       "          e\u001b[35m:f32[9]\u001b[39m = cos c\n",
       "          f\u001b[35m:f32[9]\u001b[39m = add d e\n",
       "        \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(f,) }\n",
       "      name=f\n",
       "    ] a\n",
       "  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_jaxpr(f)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf05cc39",
   "metadata": {},
   "source": [
    "This is what XLA does to your code and what Jax will see while executing it from a cache when flagged with jit.\n",
    "\n",
    "#### Now what if you do include some side effects or code unwanted by jax, for example a print statement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "453260f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T01:21:22.940168Z",
     "start_time": "2023-02-08T01:21:22.935314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traced<ShapedArray(float32[9])>with<DynamicJaxprTrace(level=1/1)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[9]\u001b[39m b\u001b[35m:f32[9]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n",
       "    \u001b[39m\u001b[22m\u001b[22mc\u001b[35m:f32[9]\u001b[39m = xla_call[\n",
       "      call_jaxpr={ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; d\u001b[35m:f32[9]\u001b[39m e\u001b[35m:f32[9]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m f\u001b[35m:f32[9]\u001b[39m = add d e \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(f,) }\n",
       "      name=side_effect_func\n",
       "    ] a b\n",
       "  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@jit\n",
    "def side_effect_func(x, y):\n",
    "    print(x)\n",
    "    x = x + y # yes this is also a side effect\n",
    "    return x\n",
    "\n",
    "make_jaxpr(side_effect_func)(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e8b7dc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T01:21:33.181956Z",
     "start_time": "2023-02-08T01:21:33.177471Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[9]\u001b[39m b\u001b[35m:f32[9]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n",
       "    \u001b[39m\u001b[22m\u001b[22mc\u001b[35m:f32[9]\u001b[39m = xla_call[\n",
       "      call_jaxpr={ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; d\u001b[35m:f32[9]\u001b[39m e\u001b[35m:f32[9]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m f\u001b[35m:f32[9]\u001b[39m = add d e \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(f,) }\n",
       "      name=without_side_effect\n",
       "    ] a b\n",
       "  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@jit\n",
    "def without_side_effect(x, y):\n",
    "    return x + y\n",
    "\n",
    "make_jaxpr(without_side_effect)(x, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c69ca1d",
   "metadata": {},
   "source": [
    "See that there's `Traced<ShapedArray(float32[9])>with<DynamicJaxprTrace(level=1/1)>` in the jaxpr output for the function with side effects. So instead of being a pure jax type, it now has a tracer type, which has to adapt to the induced side effects, the print statement and modification of x. \n",
    "\n",
    "This may not be alarm bells to you as long as you're getting correct results but this may result in inconsistent behavior acorss devices. (which jax wants to avoid at all costs). \n",
    "\n",
    "You can read more here about [jax insisting on pure functions](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#pure-functions).\n",
    "\n",
    "TL;DR : Just know that Jax is functional at core and only likes pure functions in your code. Anything else will probably run but jax can't provide you any guarantee about correct or consistent results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "85f6f424c393e7c95d987d0a64d03300802113ad2045bd4cdb9a90d6d84115f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
