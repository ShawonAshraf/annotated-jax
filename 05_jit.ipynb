{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c49b7230",
   "metadata": {},
   "source": [
    "### The magic sauce over numpy\n",
    "\n",
    "Transforms are what Jax adds on top of numpy. This is more of an advanced thing to understand and if you wish to skip and come back later, you can do it. It's fine\n",
    "\n",
    "So about transforms in Jax. There are these transforms: `jit`, `grad`, `pmap`, `vmap`.\n",
    "\n",
    "This notebook is about jit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce8614d",
   "metadata": {},
   "source": [
    "### jit()\n",
    "\n",
    "Jax calls itself accelerated numpy. Or a faster numpy. Or however you interprete it. jit is one of the key components in this acceleration. What jit does is that it keeps a copy of your functions in the cache which can be executed faster than a regular function call. But how? \n",
    "\n",
    "Okay. You asked for it. \n",
    "\n",
    "\n",
    "#### Translating computer programs (or a rather CS101 refresher)\n",
    "\n",
    "Computers only understand 1's and 0's (in other words, binary numbers). So when you try to run your code, it needs to be translated into binary numbers first. This process isn't straightforward. There are multiple levels of what CS junkies call abstractions. One possible abstraction hierarchy can be like this (or what it used to look like before [llvm](https://llvm.org/) and [clang](https://clang.llvm.org/) came). \n",
    "\n",
    "\n",
    "```\n",
    "-------> Your code \n",
    "        -------> **Translator**\n",
    "                -------> Assembler (based on the instruction Set that your CPU / GPU maker made, also known as ISA) \n",
    "                        -------> Binary (executable)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "This translator part in the middle can be either a Compiler or an Interpreter. Compiler takes your entire code file and translates it at once. There's a whole field of study in CS on compiler design if you want to look into that abyss. Anyway, since compilers translate or compile the whole file at once, you can add various optimizations (memory, speed) and enforce checks at translation or compile time to make sure your code has reduced amount of errors. Compiled programs are also, by comparison, faster. (Video Games, Operating Systems are prime examples.) **AND you need to compile only once!** (terms and conditions apply)\n",
    "\n",
    "Python on the other hand is interpreted. Interpreter translates one line at a time and **you have to intereprete everytime** you want to run your code. The process is slow and you can't enforce the same checks and optimizations like a compiler. Everything is known when the code is encountered so errors can't be reduced beforehand. So when Jax tries to cache your code for faster recall, the regular python design holds it back. Instead, Jax uses a compiler called XLA, which compiles your python code and caches it.\n",
    "\n",
    "\n",
    "And oh, JIT means just in time compilation (thank me later :) )\n",
    "\n",
    "So let's check how much of a performance benefit jit adds on top of regular code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77c46ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax as J\n",
    "from jax import jit, random\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb65fb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([-0.10502207, -0.56205004, -0.56485987, -1.7063935 ,\n",
       "             -1.3647023 , -0.42215332,  1.0077653 ,  0.9922631 ,\n",
       "             -0.61236995], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = random.PRNGKey(123)\n",
    "\n",
    "x = random.normal(key, shape=(9, ))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29a9bb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 µs ± 20.8 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return jnp.sin(x) + jnp.cos(x)\n",
    "\n",
    "%timeit f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef095714",
   "metadata": {},
   "source": [
    "With jit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a7a596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.8 µs ± 12.6 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "f_with_jit = jit(f)\n",
    "\n",
    "%timeit f_with_jit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7497cc1",
   "metadata": {},
   "source": [
    "See that wall time difference ? That's like real fast!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe078dbb",
   "metadata": {},
   "source": [
    "#### Alternate syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cefd33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.6 µs ± 6.28 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "@jit\n",
    "def f(x):\n",
    "    return jnp.sin(x) + jnp.cos(x)\n",
    "\n",
    "%timeit f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1c5b11",
   "metadata": {},
   "source": [
    "### But it's not all sunshine....\n",
    "\n",
    "Well caching and speeding up is nice but if your code changes, jit will have to compile it again. This adds some overhead and repeated compilations can make code execution slow, for example inside a loop. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036864e3",
   "metadata": {},
   "source": [
    "### What my python code becomes after XLA compilation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b12f4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import make_jaxpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05e20425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ lambda ; a:f32[9]. let\n",
       "    b:f32[9] = xla_call[\n",
       "      call_jaxpr={ lambda ; c:f32[9]. let\n",
       "          d:f32[9] = sin c\n",
       "          e:f32[9] = cos c\n",
       "          f:f32[9] = add d e\n",
       "        in (f,) }\n",
       "      name=f\n",
       "    ] a\n",
       "  in (b,) }"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_jaxpr(f)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf05cc39",
   "metadata": {},
   "source": [
    "This is what XLA does to your code and what Jax will see while executing it from a cache when flagged with jit. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
