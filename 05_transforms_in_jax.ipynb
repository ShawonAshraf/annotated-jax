{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39b6c3e1",
   "metadata": {},
   "source": [
    "### The magic sauce over numpy\n",
    "\n",
    "Transforms are what Jax adds on top of numpy. This is more of an advanced thing to understand and if you wish to skip and come back later, you can do it. It's fine\n",
    "\n",
    "So about transforms in Jax. There are these transforms: `jit`, `grad`, `pmap`, `vmap`.\n",
    "\n",
    "You've already seen `grad` in action. It makes your numpy code wrapped with jax differentiable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a1e81a",
   "metadata": {},
   "source": [
    "### jit()\n",
    "\n",
    "Jax calls itself accelerated numpy. Or a faster numpy. Or however you interprete it. jit is one of the key components in this acceleration. What jit does is that it keeps a copy of your functions in the cache which can be called in a very fast time. But how? \n",
    "\n",
    "Okay. You asked for it. \n",
    "\n",
    "\n",
    "#### Translating computer programs (or a rather CS101 refresher)\n",
    "\n",
    "Computers only understand 1's and 0's (in other words, binary numbers). So when you try to run your code, it needs to be translated into binary numbers first. This process isn't straightforward. There are multiple levels of what CS junkies call abstractions. One possible abstraction hierarchy can be like this (or what it used to look like before [llvm](https://llvm.org/) and [clang](https://clang.llvm.org/) came). \n",
    "\n",
    "\n",
    "-------> Your code \n",
    "        -------> **Translator**\n",
    "                -------> Assembler (based on the instruction Set that your CPU / GPU maker made, also known as ISA) \n",
    "                        -------> Binary\n",
    "\n",
    "\n",
    "\n",
    "This translator part in the middle can be either a Compiler or an Interpreter. Compiler takes your entire code file and translates it at once. There's a whole field of study in CS on compiler design if you want to look into that abyss. Anyway, since compilers translate or compile the whole file at once, you can add various optimizations (memory, speed) and enforce checks at translation or compile time to make sure your code has reduced amount of errors. Compiled programs are also, by comparison, faster. (Video Games, Operating Systems are prime examples.) **AND you need to compile only once!**\n",
    "\n",
    "Python on the other hand is interpreted. Interpreter translates one line at a time and **you have to intereprete everytime** you want to run your code. The process is slow and you can't enforce the same checks and optimizations like a compiler. Everything is known when the code is encountered so errors can't be reduced beforehand. So when Jax tries to cache your code for faster recall later, the regular python design holds it back. Instead, Jax uses a compiler called XLA, which compiles your python code and caches it so it can be called anytime. \n",
    "\n",
    "\n",
    "And oh, JIT means just in time compilation (thank me later :) )\n",
    "\n",
    "So let's check how much of a performance benefit jit adds on top of regular code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e756617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax as J\n",
    "from jax import jit, random\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c1f7914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([-0.10502207, -0.56205004, -0.56485987, -1.7063935 ,\n",
       "             -1.3647023 , -0.42215332,  1.0077653 ,  0.9922631 ,\n",
       "             -0.61236995], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = random.PRNGKey(123)\n",
    "\n",
    "x = random.normal(key, shape=(9, ))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeaa72ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 416 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([ 0.88966113,  0.31324244,  0.30936617, -1.1260028 ,\n",
       "             -0.7741996 ,  0.5024831 ,  1.379393  ,  1.384062  ,\n",
       "              0.24347973], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x):\n",
    "    return jnp.sin(x) + jnp.cos(x)\n",
    "\n",
    "%time f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcb41d5",
   "metadata": {},
   "source": [
    "With jit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57d0bee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 172 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([ 0.88966113,  0.31324244,  0.30936617, -1.1260028 ,\n",
       "             -0.7741996 ,  0.5024831 ,  1.379393  ,  1.384062  ,\n",
       "              0.24347973], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_with_jit = jit(f)\n",
    "\n",
    "%time f_with_jit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021b4023",
   "metadata": {},
   "source": [
    "See that wall time difference ? That's like real fast!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91c5aa44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4186046511627906"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "416 / 172"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4e56f1",
   "metadata": {},
   "source": [
    "#### Alternate syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85edcd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 68 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([ 0.88966113,  0.31324244,  0.30936617, -1.1260028 ,\n",
       "             -0.7741996 ,  0.5024831 ,  1.379393  ,  1.384062  ,\n",
       "              0.24347973], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@jit\n",
    "def f(x):\n",
    "    return jnp.sin(x) + jnp.cos(x)\n",
    "\n",
    "%time f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98378170",
   "metadata": {},
   "source": [
    "You see how it got reduced even more? Because the function is already compiled and cached. Let's try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c517140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([ 0.88966113,  0.31324244,  0.30936617, -1.1260028 ,\n",
       "             -0.7741996 ,  0.5024831 ,  1.379393  ,  1.384062  ,\n",
       "              0.24347973], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c318ee38",
   "metadata": {},
   "source": [
    "![mind blown](./images/boom-mind-blown.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d0d564",
   "metadata": {},
   "source": [
    "### But it's not all sunshine....\n",
    "\n",
    "Well caching and speeding up is nice but if your code changes, jit will have to compile it again. This adds some overhead and repeated compilations can make code execution slow, for example inside a loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a991d37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
