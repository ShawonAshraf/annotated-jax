{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mode Checkpointing\n",
    "\n",
    "So say you've trained a model, it trained fine, has a nice learning curve (train vs validation) and now you want to save it. Or, you want to save checkpoints of the model during specific stages of the training process and later, use the best checkpoints for inference. Technically, all flax modules are dataclasses and params (part of model state in flax) are what store the model, so what we need to do for checkpointing is to persist the params. \n",
    "\n",
    "However, that poses on small problem. You see, params from flax modules are not regular python data types. They're tree maps. In other libraries, e.g. Pytorch, you can save a state dict as a regular python dictionary. Such isn't compatible with flax. Instead, we use a package called [orbax](https://github.com/google/orbax) for checkpointing. \n",
    "\n",
    "Let's take the cnn from the previous notebook and add checkpointing to it. You can skip the notebook cells until the `Checkpointing` section as they have nothing to do with checkpointing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shawon/Code/jax_examples/venv/lib64/python3.12/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import jax_dataloader as jdl\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "class ToNumpy:\n",
    "    def __call__(self, x: torch.Tensor):\n",
    "        return x.numpy()\n",
    "    \n",
    "    \n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), ToNumpy()])\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainloader = jdl.DataLoader(trainset, backend=\"pytorch\", batch_size=batch_size,\n",
    "                             shuffle=True)\n",
    "testloader = jdl.DataLoader(testset, backend=\"pytorch\", batch_size=batch_size,\n",
    "                            shuffle=False)\n",
    "\n",
    "# classes in cifar10\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import flax\n",
    "import flax.linen as nn\n",
    "\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        # convs\n",
    "        out = nn.Conv(features=6, kernel_size=(5, 5))(x)\n",
    "        out = nn.max_pool(out, window_shape=(2, 2))\n",
    "        out = nn.Conv(features=16, kernel_size=(5, 5))(out)\n",
    "        out = nn.max_pool(out, window_shape=(2, 2))\n",
    "\n",
    "        # flatten into a vector\n",
    "        # skip the batch dim\n",
    "        if len(x.shape) > 3:\n",
    "            out = rearrange(x, \"batch c h w -> batch (c h w)\")\n",
    "        else:\n",
    "            out = out.flatten()\n",
    "\n",
    "        # dense\n",
    "        out = nn.Dense(features=120)(out)\n",
    "        out = nn.Dense(features=84)(out)\n",
    "        out = nn.Dense(features=10)(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "# ======================\n",
    "model = ConvNet()\n",
    "rng = jax.random.key(0)\n",
    "params = model.init(rng, jnp.empty((3, 32, 32)))\n",
    "\n",
    "# run a sample forward pass\n",
    "logits = model.apply(params, jnp.empty((3, 32, 32)))\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from flax.training import train_state\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def calculate_loss(params, x, y):\n",
    "    logits = model.apply(params, x)\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(logits, y)\n",
    "    return loss\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def batched_loss(params, xs, ys):\n",
    "    batch_loss = jax.vmap(calculate_loss, in_axes=(None, 0, 0))(params, xs, ys)\n",
    "    return batch_loss.mean(axis=-1)\n",
    "\n",
    "\n",
    "optimiser = optax.adam(learning_rate=0.001)\n",
    "criterion = jax.value_and_grad(batched_loss)\n",
    "state = train_state.TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=params,\n",
    "    tx=optimiser\n",
    ")\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    loss_value, grads = criterion(state.params, *batch)\n",
    "    updated_state = state.apply_gradients(grads=grads)\n",
    "    return loss_value, updated_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def test_step(state, xs):\n",
    "    def infer(params, x):\n",
    "        logits = model.apply(params, x)\n",
    "        return jax.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    preds = jax.vmap(jax.jit(infer), in_axes=(None, 0))(state.params, xs)\n",
    "    return preds\n",
    "\n",
    "\n",
    "def evaluate(state, test_loader):\n",
    "    scores = list()\n",
    "    for batch in tqdm(test_loader):\n",
    "        xs, ys = batch\n",
    "        preds = test_step(state, xs)\n",
    "        preds = jnp.argmax(preds, axis=-1)\n",
    "        f1 = f1_score(preds, ys, average=\"micro\")\n",
    "        scores.append(f1)\n",
    "\n",
    "    return np.array(scores).mean(axis=-1)\n",
    "\n",
    "\n",
    "def custom_classification_report(state, test_loader):\n",
    "    preds = list()\n",
    "    actual = list()\n",
    "    for batch in tqdm(test_loader):\n",
    "        xs, ys = batch\n",
    "        pred = test_step(state, xs)\n",
    "        pred = jnp.argmax(pred, axis=-1).tolist()\n",
    "        preds.extend(pred)\n",
    "        actual.extend(ys.tolist())\n",
    "\n",
    "    clf = classification_report(preds, actual, target_names=classes)\n",
    "    print(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpointing\n",
    "\n",
    "Let's first prepare orbax and then go through how checkpointing via it works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /tmp/cnn_cifar10_checkpointing_example\n",
    "# delete the existing checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import orbax\n",
    "from flax.training import orbax_utils\n",
    "\n",
    "# since everything in jax is a pytree\n",
    "# the checkpoints are basically the pytree versions of the params\n",
    "orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n",
    "# checkpoint manager for managing how many checkpoints to keep\n",
    "# keep a max of 5 checkpoints\n",
    "options = orbax.checkpoint.CheckpointManagerOptions(max_to_keep=5, create=True)\n",
    "# structure for the checkpoint\n",
    "# will be used by orbax later to restore the saved model\n",
    "# you can also add other information regarding the model\n",
    "# but make sure to keep the structure consistent\n",
    "ckpt = {\n",
    "    \"state\": state,\n",
    "}\n",
    "# tell orbax to use the structure\n",
    "save_args = orbax_utils.save_args_from_target(ckpt)\n",
    "# add the save path\n",
    "save_path = \"/tmp/cnn_cifar10_checkpointing_example\"\n",
    "# ckpt manager for versioning\n",
    "checkpoint_manager = orbax.checkpoint.CheckpointManager(save_path, orbax_checkpointer, options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breaking down the mess\n",
    "\n",
    "Since we're training using train_state from flax, we update the params with the `train_state`. So it would be wise to checkpoint the entire state instead of the params only. Now, there are two stages of checkpointing using Orbax. First, we have `PyTreeCheckpointer`, which can save a single checkpoint. It doesn't keep track of updates over training iterations so no matter how many iterations your training runs for, it'll only save a checkpoint on the first call. To track different checkpoints throughout training, we need `CheckpointManager`.\n",
    "\n",
    "Now, orbax will save the state as a pytree object. But if we want to restore a full state from it, the checkpoint manager provides no such direct API. So we have to improvise a bit (just follow through, comes right after the training function). Furthermore, orbax has no clue about the data structure of your checkpoints. All it cares is that it gets a pytree, as long as you supply the structure for it. The `ckpt` dict here provides the structure to orbax. It basically acts as a schema for the checkpoints.\n",
    "\n",
    "Sounds complicated? Kinda is. You see in Pytorch, you can just use the model class and map a saved state_dict to it. Could flax have made it simpler? May be! You can read more [here](https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html).\n",
    "\n",
    "*N.B: Checkpoint manager creates the checkpoint directory during init and maintains the directory and checkpoint metadata (paths etc.) as state. So if you want to rerun the training, delete the save_path directory first and re init the manager.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add the checkpointing code inside the `train` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(state, epochs, train_loader, test_loader, ckpt_manager=checkpoint_manager, save_args=save_args):\n",
    "    steps = 0\n",
    "    losses = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    lowest_loss = np.inf\n",
    "\n",
    "    # =============\n",
    "    for e in trange(epochs):\n",
    "        for batch in tqdm(train_loader):\n",
    "            loss, state = train_step(state, batch)\n",
    "            steps += 1\n",
    "\n",
    "            # log every 200 steps\n",
    "            if steps % 200 == 0:\n",
    "                losses.append(loss)\n",
    "\n",
    "                # run evaluation\n",
    "                print(\"Evaluating ... \")\n",
    "                score = evaluate(state, test_loader)\n",
    "\n",
    "                f1_scores.append(score)\n",
    "\n",
    "                print(f\"Epoch : {e + 1} :: Step : {steps} :: Loss : {loss} :: F1 : {score}\")\n",
    "                \n",
    "                # checkpoint only if train loss decreases\n",
    "                # ideally one would checkpoint on validation loss\n",
    "                # but we don't have a validation split on the dataset\n",
    "                # take this as an example\n",
    "            \n",
    "                if loss < lowest_loss:\n",
    "                    print(\"Checkpointing\")\n",
    "                    lowest_loss = loss\n",
    "                    # save model ckpt\n",
    "                    ckpt = {\n",
    "                        \"state\": state\n",
    "                    }\n",
    "                    ckpt_manager.save(steps, ckpt, save_kwargs={\"save_args\": save_args})\n",
    "\n",
    "    # ============\n",
    "    return state, losses, f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94543a2220f14ffd94bf618a9a7b4edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0456637d22ef49f2b88f7b098bcdf409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf368d2323b4ab8ab974fdeb76b3843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 :: Step : 200 :: Loss : 1.6986947059631348 :: F1 : 0.4495648734177215\n",
      "Checkpointing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dddf2a78ae5470b88544d9ead13913a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a5aee9511d41299b15a23670ada1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2 :: Step : 400 :: Loss : 1.507976770401001 :: F1 : 0.4664754746835443\n",
      "Checkpointing\n",
      "Evaluating ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a397e0fe8c9c4edcb71cb241156d8e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2 :: Step : 600 :: Loss : 1.4895985126495361 :: F1 : 0.4799248417721519\n",
      "Checkpointing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd168dcb319b41d58ca44a2e9a501fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b2d9de92804f648868e0d704e97150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3 :: Step : 800 :: Loss : 1.3953628540039062 :: F1 : 0.48783623417721517\n",
      "Checkpointing\n",
      "Evaluating ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a2b78a89d14cd6983a1c1d72642d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3 :: Step : 1000 :: Loss : 1.5259835720062256 :: F1 : 0.49831882911392406\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8242404f09a47ce8a6d93af483b29b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f431a522934593a30f7134a035f890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4 :: Step : 1200 :: Loss : 1.2466219663619995 :: F1 : 0.5143393987341772\n",
      "Checkpointing\n",
      "Evaluating ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eadd9127b26747a5b7d8a6dac93999d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4 :: Step : 1400 :: Loss : 1.433868408203125 :: F1 : 0.4990110759493671\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e216c13f214923b12b91409aeada9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d1e1325c9c49df94e7a8480b8dbdb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5 :: Step : 1600 :: Loss : 1.349440574645996 :: F1 : 0.5150316455696202\n",
      "Evaluating ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67ded2622db48b2884bbc64412afcc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5 :: Step : 1800 :: Loss : 1.4629029035568237 :: F1 : 0.5240308544303798\n"
     ]
    }
   ],
   "source": [
    "_, _, _ = train(state, 5, trainloader, testloader)\n",
    "# don't really need these as we'll be restoring checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check the saved checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['200', '400', '600', '800', '1200']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.listdir(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question is though, how to figure out which one is the best? If you check back on the checkpointing condition, we only saved the params when there was a new min train loss. So, based on the steps count, the last one is our best choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n"
     ]
    }
   ],
   "source": [
    "latest_step = checkpoint_manager.latest_step()\n",
    "print(latest_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to restore the model and run some inference on it. I'm just going to iterate through the test loader again here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_state_from_step(step, ckpt_manager=checkpoint_manager):\n",
    "    restored_ckpt = ckpt_manager.restore(step)\n",
    "    restored_params = restored_ckpt[\"state\"][\"params\"]\n",
    "    \n",
    "    # create a new train state object from the params\n",
    "    restored_state = train_state.TrainState.create(\n",
    "        apply_fn=model.apply,\n",
    "        params=restored_params,\n",
    "        tx=optimiser\n",
    "    )\n",
    "\n",
    "    return restored_state\n",
    "\n",
    "\n",
    "restored_state = restore_state_from_step(latest_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what we have to do to restore the model is to create an empty state (since params are part of state and that's how they're saved), use the same structure as before and then load the checkpoint from the disk and map it to the state (which is a tree_map)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b9758bd9284e9cb3515b29be9f17da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5143393987341772"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(restored_state, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33af668112d841b3a0c052ce61834ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       plane       0.59      0.53      0.56      1106\n",
      "         car       0.57      0.67      0.62       859\n",
      "        bird       0.38      0.34      0.36      1101\n",
      "         cat       0.38      0.36      0.37      1052\n",
      "        deer       0.46      0.45      0.45      1013\n",
      "         dog       0.36      0.50      0.42       721\n",
      "        frog       0.64      0.51      0.57      1251\n",
      "       horse       0.55      0.60      0.57       918\n",
      "        ship       0.67      0.63      0.65      1070\n",
      "       truck       0.55      0.60      0.57       909\n",
      "\n",
      "    accuracy                           0.51     10000\n",
      "   macro avg       0.51      0.52      0.51     10000\n",
      "weighted avg       0.52      0.51      0.51     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "custom_classification_report(restored_state, testloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
