{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import jax_dataloader as jdl\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToNumpy:\n",
    "    def __call__(self, x: torch.Tensor):\n",
    "        return x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), ToNumpy()])\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainloader = jdl.DataLoader(trainset, backend=\"pytorch\", batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "testloader = jdl.DataLoader(testset, backend=\"pytorch\", batch_size=batch_size,\n",
    "                                         shuffle=False)\n",
    "\n",
    "# classes in cifar10\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import flax\n",
    "import flax.linen as nn\n",
    "\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        # convs\n",
    "        out = nn.Conv(features=6, kernel_size=(5, 5))(x)\n",
    "        out = nn.max_pool(out, window_shape=(2, 2))\n",
    "        out = nn.Conv(features=16, kernel_size=(5, 5))(out)\n",
    "        out = nn.max_pool(out, window_shape=(2, 2))\n",
    "\n",
    "\n",
    "        # flatten into a vector \n",
    "        # skip the batch dim\n",
    "        if len(x.shape) > 3:\n",
    "            out = rearrange(x, \"batch c h w -> batch (c h w)\")\n",
    "        else:\n",
    "            out = out.flatten()\n",
    "\n",
    "        # dense\n",
    "        out = nn.Dense(features=120)(out)\n",
    "        out = nn.Dense(features=84)(out)\n",
    "        out = nn.Dense(features=10)(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvNet()\n",
    "rng = jax.random.key(0)\n",
    "params = model.init(rng, jnp.empty((3, 32, 32)))\n",
    "\n",
    "# run a sample forward pass\n",
    "logits = model.apply(params, jnp.empty((3, 32, 32)))\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "from tqdm.auto import trange, tqdm\n",
    "from flax.training import train_state\n",
    "from functools import partial\n",
    "\n",
    "@jax.jit\n",
    "def calculate_loss(params, x, y):\n",
    "    logits = model.apply(params, x)\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(logits, y)\n",
    "    return loss\n",
    "\n",
    "@jax.jit\n",
    "def batched_loss(params, xs, ys):\n",
    "    batch_loss = jax.vmap(calculate_loss, in_axes=(None, 0, 0))(params, xs, ys)\n",
    "    return batch_loss.mean(axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "optimiser = optax.adam(learning_rate=0.001)\n",
    "state = train_state.TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=params,\n",
    "    tx=optimiser\n",
    ")\n",
    "criterion = jax.value_and_grad(batched_loss)\n",
    "\n",
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    loss_value, grads = criterion(state.params, *batch)\n",
    "    updated_state = state.apply_gradients(grads=grads)\n",
    "    return loss_value, updated_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up checkpointing for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import orbax\n",
    "from flax.training import orbax_utils\n",
    "\n",
    "# since everything in jax is a pytree\n",
    "# the checkpoints are basically the pytree versions of the params\n",
    "orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n",
    "\n",
    "# checkpoint manager for managing how many checkpoints to keep\n",
    "# keep a max of 2 checkpoints\n",
    "options = orbax.checkpoint.CheckpointManagerOptions(max_to_keep=5, create=True)\n",
    "\n",
    "# add the save path\n",
    "save_path = \"/tmp/cnn_ckpt\"\n",
    "checkpoint_manager = orbax.checkpoint.CheckpointManager(save_path, orbax_checkpointer, options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create save args for checkpoint_manager\n",
    "ckpt = {\n",
    "    \"model\": state,\n",
    "    # \"model_prngs\": rng\n",
    "}\n",
    "save_args = orbax_utils.save_args_from_target(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "\n",
    "def train(state, epochs, train_loader, test_loader):\n",
    "    steps = 0\n",
    "    losses = []\n",
    "    # f1s = []\n",
    "\n",
    "    # =============\n",
    "    for e in trange(epochs):\n",
    "        for batch in tqdm(train_loader):\n",
    "            loss, state = train_step(state, batch)\n",
    "            steps += 1\n",
    "\n",
    "            # log every 200 steps\n",
    "            if steps % 200 == 0:\n",
    "                losses.append(loss)\n",
    "                \n",
    "                # run evaluation\n",
    "                print(\"Evaluating ... \")\n",
    "                # score = evaluate(state, test_loader)\n",
    "                \n",
    "                # f1s.append(score)\n",
    "    \n",
    "                print(f\"Epoch : {e + 1} :: Step : {steps} :: Loss : {loss}\")\n",
    "        \n",
    "        # save model ckpt\n",
    "        checkpoint_manager.save(steps, ckpt, save_kwargs={\"save_args\": save_args})\n",
    "        # orbax_checkpointer.save(f\"{save_path}/{steps}\", ckpt, save_args=save_args)\n",
    "    # ============\n",
    "    return state, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /tmp/cnn_ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a692b9d4d4904876869c4e602d20e90a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc6fa98af054709b67f7ae70732f98a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating ... \n",
      "Epoch : 1 :: Step : 200 :: Loss : 1.2740516662597656\n"
     ]
    }
   ],
   "source": [
    "state, losses = train(state, 1, trainloader, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_step = checkpoint_manager.latest_step()\n",
    "latest_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_restored = checkpoint_manager.restore(latest_step)\n",
    "restored_params = raw_restored[\"model\"][\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "restored_state = train_state.TrainState.create(\n",
    "        apply_fn=model.apply,\n",
    "        params=restored_params,\n",
    "        tx=optimiser\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# ckpt_path = os.path.join(save_path, str(latest_step))\n",
    "\n",
    "# # but these are raw dicts and we need pytrees\n",
    "# # the process outlined in the orbax docs is cumbersome\n",
    "# # like why google? why?\n",
    "# def restore_from_raw_checkpoint(latest_step):\n",
    "#     empty_state = train_state.TrainState.create(\n",
    "#         apply_fn=model.apply,\n",
    "#         params=jax.tree_map(np.zeros_like, params),\n",
    "#         tx=optimiser\n",
    "#     )\n",
    "    \n",
    "#     # same as the save_args\n",
    "#     target = {\"model\": empty_state}\n",
    "    \n",
    "#     latest_ckpt = checkpoint_manager.restore(latest_step, target)    \n",
    "    \n",
    "#     state_restored = orbax_checkpointer.restore(ckpt_path, item=target)\n",
    "    \n",
    "#     return state_restored\n",
    "\n",
    "# restored_state = restore_from_raw_checkpoint(latest_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "@jax.jit\n",
    "def test_step(state, xs):\n",
    "    def infer(params, x):\n",
    "        logits = model.apply(params, x)\n",
    "        return jax.nn.softmax(logits, axis=-1) \n",
    "\n",
    "    preds = jax.vmap(jax.jit(infer), in_axes=(None, 0))(state.params, xs)\n",
    "    return preds\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(state, test_loader):\n",
    "    scores = list()\n",
    "    for batch in tqdm(test_loader):\n",
    "        xs, ys = batch\n",
    "        preds = test_step(state, xs)\n",
    "        preds = jnp.argmax(preds, axis=-1)\n",
    "        f1 = f1_score(preds, ys, average=\"micro\")\n",
    "        scores.append(f1)\n",
    "\n",
    "    return np.array(scores).mean(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "066af9b444054f6ab471b23d7ba302b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5327333860759493"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the evaluation function\n",
    "# should've named state but anyway\n",
    "evaluate(restored_state, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
