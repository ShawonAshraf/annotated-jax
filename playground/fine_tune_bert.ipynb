{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading, sit tight!\n",
      ">> Downloading review_polarity.tar.gz 100.06734377108491%%\n",
      "Successfully downloaded review_polarity.tar.gz 3127238 bytes\n",
      "\n",
      "Unzipping ...\n",
      "Deleting downloaded zip file\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib\n",
    "import tarfile\n",
    "import shutil\n",
    "\n",
    "\n",
    "corpus_url = \"http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\"\n",
    "\n",
    "corpus_root = \"/tmp/review_polarity/\"\n",
    "extracted_path = os.path.join(corpus_root, \"extracted\")\n",
    "if os.path.exists(corpus_root):\n",
    "    shutil.rmtree(corpus_root)\n",
    "if os.path.exists(extracted_path):\n",
    "    shutil.rmtree(extracted_path)\n",
    "\n",
    "os.makedirs(corpus_root)\n",
    "\n",
    "\n",
    "catgeories = [\"pos\", \"neg\"]\n",
    "\n",
    "\n",
    "def download_and_unzip():\n",
    "    file_name = corpus_url.split(\"/\")[-1]\n",
    "    download_path = os.path.join(corpus_root, file_name)\n",
    "\n",
    "    # ============================================ download\n",
    "    print(\"Downloading, sit tight!\")\n",
    "\n",
    "    def _progress(count, block_size, total_size):\n",
    "        sys.stdout.write(\n",
    "            f\"\\r>> Downloading {file_name} {float(count * block_size) / float(total_size) * 100.0}%\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    file_path, _ = urllib.request.urlretrieve(\n",
    "        corpus_url, download_path, _progress)\n",
    "    print()\n",
    "    print(\n",
    "        f\"Successfully downloaded {file_name} {os.stat(file_path).st_size} bytes\")\n",
    "\n",
    "    # ======================================= unzip\n",
    "    print()\n",
    "    print(\"Unzipping ...\")\n",
    "    # create dir at extracted_path\n",
    "    os.mkdir(extracted_path)\n",
    "    tarfile.open(file_path, \"r:gz\").extractall(extracted_path)\n",
    "\n",
    "    # =========================================== clean up\n",
    "    # delete the downloaded zip file\n",
    "    print(\"Deleting downloaded zip file\")\n",
    "    os.remove(file_path)\n",
    "\n",
    "\n",
    "# =============\n",
    "def read_text_files(path):\n",
    "    file_list = os.listdir(path)\n",
    "    texts = []\n",
    "\n",
    "    for fname in file_list:\n",
    "        fpath = os.path.join(path, fname)\n",
    "\n",
    "        f = open(fpath, mode=\"r\")\n",
    "        lines = f.read()\n",
    "        texts.append(lines)\n",
    "        f.close()\n",
    "\n",
    "    return texts\n",
    "\n",
    "\n",
    "# =========\n",
    "download_and_unzip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f59debafb73483fb49dc7cc1158e6e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "prepare_corpus:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ada853cd2824f1d9d1aa8d61fba2bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "prepare_corpus:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "reviews = []\n",
    "labels = []\n",
    "\n",
    "# we can't use the previous tokenizers here\n",
    "# idx 0 -> neg, 1 -> pos\n",
    "for idx, cat in enumerate(catgeories):\n",
    "    path = os.path.join(extracted_path, \"txt_sentoken\", cat)\n",
    "    texts = read_text_files(path)\n",
    "\n",
    "    for i in tqdm(range(len(texts)), desc=\"prepare_corpus\"):\n",
    "        text = texts[i]\n",
    "        reviews.append(text)\n",
    "        labels.append(idx)\n",
    "\n",
    "print()\n",
    "print(len(reviews))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    reviews, labels, random_state=42, train_size=0.8\n",
    ")\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train, y_train, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import FlaxAutoModel, AutoTokenizer\n",
    "import jax\n",
    "import flax.linen as nn\n",
    "import jax.numpy as np\n",
    "import numpy as onp\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': Array([[  101,  2023,  2003, 24369,  3793,   102]], dtype=int32), 'token_type_ids': Array([[0, 0, 0, 0, 0, 0]], dtype=int32), 'attention_mask': Array([[1, 1, 1, 1, 1, 1]], dtype=int32)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"google-bert/bert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "clear_output()\n",
    "\n",
    "text = \"this is dummy text\"\n",
    "encoded = tokenizer.encode_plus(text, return_tensors=\"jax\")\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[\"attention_mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  101, 12633,  2051,  1024,  1045,  2031,  2196,  1010,  2412,\n",
       "          2464,  2908,  2007,  1996,  3612,  1012,  1045,  2123,  1005,\n",
       "          1056,  2113,  2339,  1010,  2428,  1012,  4033,  1005,  1056,\n",
       "          2359,  2000,  4638,  2009,  2041,  2006,  2678,  1010,  4033,\n",
       "          1005,  1056,  2042,  2012,  2188,  1996,  6385,  2009,  2001,\n",
       "          2006,  2897,  2694,  1010,  1998,  2009,  2001,  2205,  2521,\n",
       "          2000,  3298,  1996,  2197,  2051,  2009,  2001,  2006,  1996,\n",
       "          2502,  1011,  3898,  1012,  2061,  2157,  2039,  2392,  1010,\n",
       "          1045,  1005,  2222,  6449,  2008,  1045,  2123,  1005,  1056,\n",
       "          2113,  2054,  1996, 17752,  1045,  1005,  1049,  3331,  2055,\n",
       "          1010,  2021,  2182,  3632,  1012,  1012,  1012,  2003, 20753,\n",
       "          1996,  2908,  2007,  1996,  3612,  1997,  1996,  2901,  1005,\n",
       "          1055,  1029,  2672,  2008,  1005,  1055,  2183,  1037,  2210,\n",
       "          2978,  2205,  2521,  1012,  2004,  2204,  1037,  3105,  2004,\n",
       "         14720,  4487, 17695,  9488,  1998,  5736,  5222,  7485,  2079,\n",
       "          1999,  2023,  3185,  1010,  2027,  1005,  2128,  2053,  5215,\n",
       "         13733,  1998,  6819, 13469,  2078, 11797,  1012,  2021,  1012,\n",
       "          1012,  1012,  1996, 18588,  2024,  2045,  1012,  1043, 26677,\n",
       "          2860,  2001,  1996,  2034,  3185,  2000,  2202,  2613,  5056,\n",
       "          1997,  1996,  2087,  6208,  2974,  2800,  1011,  1011,  6627,\n",
       "          8713, 12898,  2099,  1012, 20753,  3138,  6208,  4084,  2830,\n",
       "          1999, 25180, 10895, 22380,  3274,  8425,  2640,  2007,  5889,\n",
       "          1012,  1043, 26677,  2860,  3182,  2637,  1005,  1055,  4602,\n",
       "         10576,  1999,  1996,  4281,  1997,  1037,  4438,  2293,  2466,\n",
       "          1010, 20753,  2515,  1996,  2168,  2007,  1996,  4448,  1005,\n",
       "          1055,  2087,  8987, 10576,  1012,  2027,  2119,  2031,  2844,\n",
       "          1011, 22705, 26705,  2098, 18869,  2015,  1010,  2027,  2119,\n",
       "         18077,  1996,  2465,  5966,  2090,  1996, 22706,  1998,  1996,\n",
       "          7179,  1013, 20634,  4270, 26352,  2015,  1010,  2027,  2020,\n",
       "          2119, 11757,  6450,  1998,  2759,  1012,  1012,  1012,  7929,\n",
       "          1010,  2672,  2008,  1005,  1055,  2025,  2438, 18588,  1012,\n",
       "          2061, 20753,  1005,  1055,  2025,  1999,  1043, 26677,  2860,\n",
       "          1005,  1055,  2223,  1012,  2053,  3043,  1012, 20753,  2003,\n",
       "          1037,  2307,  3185,  1999,  2049,  2219,  2157,  1010,  3143,\n",
       "          2007, 14437,  2015,  1010, 16959,  2015,  1998,  1006,  2926,\n",
       "          1007, 10720,  2015,  1012,  2172,  2038,  2042,  2081,  1997,\n",
       "          1996, 14910,  5063,  3560,  3465,  1997,  1996,  2537,  1010,\n",
       "          1998,  2035,  1997,  1996,  2729,  2084,  2253,  2046,  2437,\n",
       "          1996,  4121,  9542, 11197,  2272,  4142,  2153,  1012,  1996,\n",
       "          2769,  2001,  5525,  2092,  1011,  2985,  1012,  1996, 12703,\n",
       "          2298,  2307,  1010,  1996,  4520,  2298,  2307,  1010,  1996,\n",
       "          1039,  5856,  8389,  2298,  2307,  1012,  1045,  2926,  4669,\n",
       "          1996,  6450,  2210, 12817,  1010,  2066,  5938,  6197,  1997,\n",
       "          2769,  2006, 14469, 20753,  2859,  2069,  2000,  3338,  2009,\n",
       "          2035,  2006,  1996,  2723,  2004,  1996,  2911, 23462,  1012,\n",
       "          2021,  3213,  1013,  2472,  1013,  3135,  2508,  7232,  1005,\n",
       "          1055,  2613,  4119,  1999,  3015,  1013,  9855,  1013,  5155,\n",
       "         20753,  2347,  1005,  1056,  2074,  3465, 24270,  1998,  2275,\n",
       "          2640,  1998,  2569,  3896,  1012,  7232,  1005,  1055,  2350,\n",
       "         14978,  2001,  4363,  1996,  4378,  4699,  1999,  1037,  6925,\n",
       "          2073,  7955,  4282,  1996,  4566,  2183,  1999,  1012,  2002,\n",
       "         21645,  3040,  7699,  1012,  7232,  2515,  2048,  2477,  2008,\n",
       "          2147, 11757,  2092,  1012,  2034,  1010,  2002,  3065,  2149,\n",
       "          2715,  1011,  2154, 18340,  3136,  2006, 20753,  1006,  2008,\n",
       "          1005,  1055,  2074,  1000, 20753,  1000,  1010,  2025,  1000,\n",
       "          1996, 20753,  1000,  1010,  2568,  2017,  1007,  1012,  1996,\n",
       "          2034, 12185,  2057,  2131,  1997, 20753,  2003,   102]]),\n",
       " array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1]]),\n",
       " array([0]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "\n",
    "class PolarityReviewDataset(Dataset):\n",
    "\n",
    "    def __init__(self, reviews, labels, tokenizer):\n",
    "        self.reviews = reviews\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        review = self.reviews[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # encode review text\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"np\"\n",
    "        )\n",
    "        \n",
    "        return encoding[\"input_ids\"], encoding[\"attention_mask\"], onp.array([label])\n",
    "\n",
    "\n",
    "training_dataset = PolarityReviewDataset(x_train, y_train, tokenizer)\n",
    "val_dataset = PolarityReviewDataset(x_val, y_val, tokenizer)\n",
    "\n",
    "training_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax_dataloader as jdl\n",
    "\n",
    "BS = 16\n",
    "\n",
    "train_loader = jdl.DataLoader(training_dataset, \"pytorch\", batch_size=BS, shuffle=True)\n",
    "val_loader = jdl.DataLoader(\n",
    "    val_dataset, \"pytorch\", batch_size=BS, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://flax.readthedocs.io/en/latest/guides/training_techniques/transfer_learning.html\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "def load_model(model_name):\n",
    "    model = FlaxAutoModel.from_pretrained(model_name)\n",
    "    # clear_output()\n",
    "    module = model.module\n",
    "    variables = {\"params\": model.params}\n",
    "    return module, variables\n",
    "\n",
    "bert_module, bert_vars = load_model(model_name)\n",
    "\n",
    "\n",
    "class SentimentCLF(nn.Module):\n",
    "    backbone: nn.Module\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, input_ids: np.ndarray, attention_mask: np.ndarray) -> Any:\n",
    "        out = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        out = out.pooler_output\n",
    "        out = nn.Dense(2)(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "rng = jax.random.key(0)\n",
    "model = SentimentCLF(bert_module)\n",
    "\n",
    "sample_data = training_dataset[0]\n",
    "input_ids, attention_mask, label = sample_data\n",
    "initial_params = model.init(rng, input_ids, attention_mask)\n",
    "\n",
    "# add pretrained vars\n",
    "initial_params[\"backbone\"] = bert_vars[\"params\"]\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "\n",
    "@jax.jit\n",
    "def calculate_loss(params, input_ids, attention_mask, label):\n",
    "    logits = model.apply(params, input_ids, attention_mask)\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(logits, label)\n",
    "    # typical numpy array thing\n",
    "    # should be a scalar\n",
    "    return loss[0]\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def batched_loss(params, input_ids, attention_masks, labels):\n",
    "    batch_loss = jax.vmap(calculate_loss, in_axes=(None, 0, 0, 0))(params, input_ids, attention_masks, labels)\n",
    "    return batch_loss.mean(axis=-1)\n",
    "\n",
    "\n",
    "# =========\n",
    "# single_loss = calculate_loss(initial_params, input_ids, attention_mask, label)\n",
    "# print(f\"{single_loss=}\")\n",
    "\n",
    "# for batch in train_loader:\n",
    "#     input_ids, attention_masks, labels = batch\n",
    "#     batch_loss = batched_loss(initial_params, input_ids, attention_masks, labels)\n",
    "#     print(f\"{batch_loss=}\")\n",
    "#     break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.training import train_state\n",
    "    \n",
    "clipper = optax.clip_by_global_norm(1.0)\n",
    "\n",
    "tx = optax.chain(optax.adam(learning_rate=2e-5), optax.clip_by_global_norm(1.0))\n",
    "\n",
    "initial_state = train_state.TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    tx=tx,\n",
    "    params=initial_params,\n",
    ")\n",
    "criterion = jax.value_and_grad(batched_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    input_ids, attention_masks, labels = batch\n",
    "    loss_value, grads = criterion(state.params, input_ids, attention_masks, labels)    \n",
    "    updated_state = state.apply_gradients(grads=grads)\n",
    "    return loss_value, updated_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def validation_step(state, batch):\n",
    "    input_ids, attention_masks, labels = batch\n",
    "    loss_value, _ = criterion(state.params, input_ids, attention_masks, labels)\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c79d696ad74f6a872ad54484a60aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e905fdbe694862879949567212b707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_step:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7d4eac059d459890abbfdff1db8616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation_step:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 :: Step : 40 :: Loss/Train : 0.7023136615753174 :: Loss/Validation : 0.7341246604919434\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ddd83ae80bd46ae9592321679a3f9f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation_step:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 :: Step : 80 :: Loss/Train : 0.7774825096130371 :: Loss/Validation : 0.6911054849624634\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f446d9dcfc434faf145f6074f5ee59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_step:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23fd8f11012d4cd4b6aa29d48cda9659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation_step:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2 :: Step : 120 :: Loss/Train : 0.7025219798088074 :: Loss/Validation : 0.6906630396842957\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a187adac9045489828518e37fc1852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation_step:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2 :: Step : 160 :: Loss/Train : 0.6867724657058716 :: Loss/Validation : 0.6897759437561035\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef1d2e7717a45ee8d83b1e6de3af03b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_step:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebcbf01a30bf4a0e89d865e287d4de95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation_step:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3 :: Step : 200 :: Loss/Train : 0.6646379232406616 :: Loss/Validation : 0.7070509791374207\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf91104f788c42c6a003078b2e16a992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation_step:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3 :: Step : 240 :: Loss/Train : 0.6788275241851807 :: Loss/Validation : 0.6963270902633667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32e2aaca01149429cb2a1a6cc60ecd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_step:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24861221f11f45ee920fe3e108dab66f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation_step:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4 :: Step : 280 :: Loss/Train : 0.6922473907470703 :: Loss/Validation : 0.6929025650024414\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c6e4d3b2b14a508d735d60401b83c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation_step:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4 :: Step : 320 :: Loss/Train : 0.8465610146522522 :: Loss/Validation : 0.7449512481689453\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f27c2cbc0a9740c3bfbf86cf91404dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_step:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d5a071f0e9e45ee9ae88308d1d11234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation_step:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5 :: Step : 360 :: Loss/Train : 0.6806708574295044 :: Loss/Validation : 0.687907338142395\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf91db16fdc402496140d4135a41aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation_step:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5 :: Step : 400 :: Loss/Train : 0.732725203037262 :: Loss/Validation : 0.7068235278129578\n"
     ]
    }
   ],
   "source": [
    "def train(state, epochs, train_loader, val_loader):\n",
    "    steps = 0\n",
    "    train_losses = []\n",
    "    mean_val_losses = []\n",
    "\n",
    "\n",
    "    # =============\n",
    "    for e in trange(epochs):\n",
    "        for batch in tqdm(train_loader, desc=\"train_step\"):\n",
    "            train_loss, state = train_step(state, batch)\n",
    "            steps += 1\n",
    "\n",
    "            # log every 200 steps\n",
    "            if steps % 40 == 0:\n",
    "                train_losses.append(train_loss)\n",
    "\n",
    "                # run validation\n",
    "                validation_losses = []\n",
    "                for batch in tqdm(val_loader, desc=\"validation_step\"):\n",
    "                    val_loss = validation_step(state, batch)\n",
    "                    validation_losses.append(val_loss)\n",
    "                    \n",
    "                mean_val_loss = onp.array(validation_losses).mean(axis=-1)\n",
    "                mean_val_losses.append(mean_val_loss)\n",
    "\n",
    "\n",
    "                print(\n",
    "                    f\"Epoch : {e + 1} :: Step : {steps} :: Loss/Train : {train_loss} :: Loss/Validation : {mean_val_loss}\")\n",
    "                \n",
    "    # ============\n",
    "    return state, train_losses, mean_val_losses\n",
    "\n",
    "# ============\n",
    "trained_state, train_losses, mean_val_losses = train(initial_state, 5, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = PolarityReviewDataset(x_test, y_test, tokenizer)\n",
    "test_loader = jdl.DataLoader(test_dataset, \"pytorch\", batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23992be66c7243a19985d73e1a1e1d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6613845226434726"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def test_step(state, batch):\n",
    "    input_ids, attention_masks, labels = batch\n",
    "\n",
    "    def infer(params, input_ids, attention_mask):\n",
    "        logits = model.apply(params, input_ids, attention_mask)\n",
    "        return jax.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    probas = jax.vmap(jax.jit(infer), in_axes=(None, 0, 0))(\n",
    "        state.params, input_ids, attention_masks)\n",
    "\n",
    "    return probas\n",
    "\n",
    "\n",
    "def evaluate(state, test_loader):\n",
    "    scores = list()\n",
    "    for batch in tqdm(test_loader):\n",
    "        _, _, labels = batch\n",
    "        probas = test_step(state, batch)\n",
    "        preds = onp.argmax(probas, axis=-1)\n",
    "        f1s = f1_score(labels, preds)\n",
    "\n",
    "        scores.append(f1s)\n",
    "\n",
    "    return onp.array(scores).mean(axis=-1)\n",
    "\n",
    "# ===========\n",
    "evaluate(trained_state, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
